{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a233b909",
   "metadata": {},
   "source": [
    "# Laboratorio 1 (AlpesHearth): Exploración, preparación y regresión lineal\n",
    "\n",
    "Este notebook está diseñado para cumplir el enunciado completo:\n",
    "\n",
    "1. Exploración y perfilamiento (calidad: completitud, unicidad, consistencia, validez).\n",
    "2. Limpieza y preparación con justificación.\n",
    "3. Dos modelos de regresión lineal con **pipelines** y preparación distinta.\n",
    "4. Tabla comparativa en test con **RMSE, MAE y R2**.\n",
    "5. Importancia de variables con base en el mejor modelo (coeficientes).\n",
    "6. Validación de supuestos (gráficos de residuos) para apoyar interpretación.\n",
    "7. Predicción sobre el archivo de test no etiquetado y exportación en CSV.\n",
    "\n",
    "Nota importante (causa típica de R2 negativo):\n",
    "- La columna **`Blood Pressure (mmHg)`** viene como texto tipo `\"120/80\"`. Si se deja como categórica, crea miles de dummies y generaliza muy mal.\n",
    "- Aquí la usamos solo para **completar** `Systolic BP` y `Diastolic BP`, y luego la excluimos del modelado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c11ed",
   "metadata": {},
   "source": [
    "## 0. Imports y constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e3937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.25\n",
    "\n",
    "TARGET = \"CVD Risk Score\"\n",
    "AUX_LABEL = \"CVD Risk Level\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a07245",
   "metadata": {},
   "source": [
    "## 1. Cargar datos y diccionario\n",
    "\n",
    "Punto clave: `Datos Test Lab 1.csv` usa `;` y el train usa `,`. Esta celda detecta el separador automáticamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41cf99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_csv_auto_sep(path: str) -> pd.DataFrame:\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        first_line = f.readline()\n",
    "    sep = \";\" if first_line.count(\";\") > first_line.count(\",\") else \",\"\n",
    "    return pd.read_csv(path, sep=sep)\n",
    "\n",
    "train_path = \"Datos Lab 1.csv\"\n",
    "test_path  = \"Datos Test Lab 1.csv\"\n",
    "dicc_path  = \"DiccPacientes.xlsx\"\n",
    "\n",
    "train_raw = read_csv_auto_sep(train_path)\n",
    "test_raw  = read_csv_auto_sep(test_path)\n",
    "dicc_raw  = pd.read_excel(dicc_path)\n",
    "dicc_raw.columns = [c.strip() for c in dicc_raw.columns]\n",
    "\n",
    "print(\"Train shape:\", train_raw.shape)\n",
    "print(\"Test  shape:\", test_raw.shape)\n",
    "display(dicc_raw.head(10))\n",
    "\n",
    "print(\"Columnas extra en train (vs test):\", sorted(list(set(train_raw.columns) - set(test_raw.columns))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d2b5d",
   "metadata": {},
   "source": [
    "## 2. Exploración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cade77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(train_raw.head())\n",
    "display(test_raw.head())\n",
    "\n",
    "print(\"Tipos de datos (train):\")\n",
    "display(train_raw.dtypes)\n",
    "\n",
    "print(\"Describe numérico (train):\")\n",
    "display(train_raw.select_dtypes(include=[np.number]).describe())\n",
    "\n",
    "print(\"Describe del target (train):\")\n",
    "display(train_raw[TARGET].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68a764",
   "metadata": {},
   "source": [
    "## 3. Perfilamiento de calidad (completitud, unicidad, consistencia, validez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Completitud\n",
    "missing_train = (train_raw.isna().mean() * 100).sort_values(ascending=False)\n",
    "missing_test  = (test_raw.isna().mean() * 100).sort_values(ascending=False)\n",
    "\n",
    "print(\"Missing % (train) - top 15\")\n",
    "display(missing_train.head(15))\n",
    "\n",
    "print(\"Missing % (test) - top 15\")\n",
    "display(missing_test.head(15))\n",
    "\n",
    "print(\"Filas en train con target missing:\", train_raw[TARGET].isna().sum())\n",
    "\n",
    "# Unicidad\n",
    "print(\"Duplicados exactos train:\", train_raw.duplicated().sum())\n",
    "print(\"Duplicados exactos test :\", test_raw.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11734bad",
   "metadata": {},
   "source": [
    "### 3.1 Consistencia (categóricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CAT_COLS = [\n",
    "    \"Sex\",\n",
    "    \"Smoking Status\",\n",
    "    \"Diabetes Status\",\n",
    "    \"Physical Activity Level\",\n",
    "    \"Family History of CVD\",\n",
    "    \"Blood Pressure Category\",\n",
    "]\n",
    "\n",
    "for c in CAT_COLS:\n",
    "    print(\"\\n---\", c, \"---\")\n",
    "    display(train_raw[c].astype(str).value_counts().head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7548ae45",
   "metadata": {},
   "source": [
    "### 3.2 Validez (valores imposibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7bba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"LDL negativo (train):\", (train_raw[\"Estimated LDL (mg/dL)\"] < 0).sum())\n",
    "print(\"Colesterol total negativo (train):\", (train_raw[\"Total Cholesterol (mg/dL)\"] < 0).sum())\n",
    "\n",
    "print(\"Peso <= 0 (train):\", (train_raw[\"Weight (kg)\"] <= 0).sum(skipna=True))\n",
    "print(\"Altura (m) <= 0 (train):\", (train_raw[\"Height (m)\"] <= 0).sum(skipna=True))\n",
    "print(\"Edad <= 0 (train):\", (train_raw[\"Age\"] <= 0).sum(skipna=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cffa06e",
   "metadata": {},
   "source": [
    "## 4. Limpieza y preparación (justificada)\n",
    "\n",
    "Reglas:\n",
    "- Quitar duplicados exactos.\n",
    "- Quitar filas sin `CVD Risk Score` en train.\n",
    "- LDL negativo y colesterol total negativo se vuelven NaN.\n",
    "- Completar `Systolic BP` y `Diastolic BP` desde `Blood Pressure (mmHg)` si es posible.\n",
    "- Normalizar categóricas con `strip()`.\n",
    "\n",
    "Importante:\n",
    "- `Blood Pressure (mmHg)` se usa para completar BP numérica, pero **NO** se usa como predictor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f872450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_bp_series(series: pd.Series):\n",
    "    sys_vals, dia_vals = [], []\n",
    "    for v in series.astype(str):\n",
    "        m = re.match(r\"^\\s*(\\d+)\\s*/\\s*(\\d+)\\s*$\", v)\n",
    "        if m:\n",
    "            sys_vals.append(float(m.group(1)))\n",
    "            dia_vals.append(float(m.group(2)))\n",
    "        else:\n",
    "            sys_vals.append(np.nan)\n",
    "            dia_vals.append(np.nan)\n",
    "    return pd.Series(sys_vals, index=series.index), pd.Series(dia_vals, index=series.index)\n",
    "\n",
    "def normalize_categories(df: pd.DataFrame, cat_cols: list[str]) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].astype(\"string\").str.strip()\n",
    "    return df\n",
    "\n",
    "def clean_common(df: pd.DataFrame, cat_cols: list[str] = None) -> pd.DataFrame:\n",
    "    if cat_cols is None:\n",
    "        cat_cols = CAT_COLS\n",
    "\n",
    "    df = df.copy()\n",
    "    df = normalize_categories(df, cat_cols)\n",
    "\n",
    "    # Validez\n",
    "    df.loc[df[\"Estimated LDL (mg/dL)\"] < 0, \"Estimated LDL (mg/dL)\"] = np.nan\n",
    "    df.loc[df[\"Total Cholesterol (mg/dL)\"] < 0, \"Total Cholesterol (mg/dL)\"] = np.nan\n",
    "\n",
    "    # Completar BP numérica desde el string\n",
    "    if \"Blood Pressure (mmHg)\" in df.columns:\n",
    "        sys_bp, dia_bp = parse_bp_series(df[\"Blood Pressure (mmHg)\"])\n",
    "        df[\"Systolic BP\"] = df[\"Systolic BP\"].fillna(sys_bp)\n",
    "        df[\"Diastolic BP\"] = df[\"Diastolic BP\"].fillna(dia_bp)\n",
    "\n",
    "    return df\n",
    "\n",
    "train = train_raw.drop_duplicates().dropna(subset=[TARGET]).copy()\n",
    "train = clean_common(train)\n",
    "\n",
    "test = test_raw.drop_duplicates().copy()\n",
    "test = clean_common(test)\n",
    "\n",
    "print(\"Train limpio shape:\", train.shape)\n",
    "print(\"Test  limpio shape:\", test.shape)\n",
    "\n",
    "print(\"LDL negativo (train limpio):\", (train[\"Estimated LDL (mg/dL)\"] < 0).sum(skipna=True))\n",
    "print(\"Colesterol total negativo (train limpio):\", (train[\"Total Cholesterol (mg/dL)\"] < 0).sum(skipna=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a1e95",
   "metadata": {},
   "source": [
    "## 5. Visualizaciones útiles (target y correlaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb624d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(train[TARGET], kde=True)\n",
    "plt.title(\"Distribución de CVD Risk Score\")\n",
    "plt.xlabel(TARGET)\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()\n",
    "\n",
    "corr = train.select_dtypes(include=[np.number]).corr()\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Heatmap de correlación (numéricas)\")\n",
    "plt.show()\n",
    "\n",
    "target_corr = corr[TARGET].drop(TARGET).abs().sort_values(ascending=False)\n",
    "display(target_corr.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ca4794",
   "metadata": {},
   "source": [
    "## 6. Definir X, y y partición train-test (enunciado: semilla 42 y 25%)\n",
    "\n",
    "Decisión crítica (para evitar R2 negativo):\n",
    "- Excluimos `Blood Pressure (mmHg)` del modelado porque es texto con alta cardinalidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b64d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DROP_ALWAYS = [\"Patient ID\", \"Date of Service\", AUX_LABEL, \"Blood Pressure (mmHg)\"]\n",
    "\n",
    "X = train.drop(columns=[TARGET] + DROP_ALWAYS).copy()\n",
    "y = train[TARGET].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"X_test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523365b9",
   "metadata": {},
   "source": [
    "## 7. Dos modelos (pipelines) con preparación distinta\n",
    "\n",
    "Modelo 1 (baseline OLS):\n",
    "- Imputación + OneHot + LinearRegression\n",
    "\n",
    "Modelo 2 (RidgeCV):\n",
    "- Imputación + escalado numérico + OneHot + RidgeCV (regresión lineal regularizada)\n",
    "\n",
    "Por qué Ridge aquí:\n",
    "- Sigue siendo regresión lineal.\n",
    "- Ayuda con multicolinealidad y alta dimensionalidad por dummies, mejora generalización.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f5c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_preprocess(X_sample: pd.DataFrame, scale_numeric: bool) -> ColumnTransformer:\n",
    "    num_cols = X_sample.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = [c for c in X_sample.columns if c not in num_cols]\n",
    "\n",
    "    num_steps = [(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    "    if scale_numeric:\n",
    "        num_steps.append((\"scaler\", StandardScaler()))\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", Pipeline(num_steps), num_cols),\n",
    "            (\"cat\", Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\")),\n",
    "            ]), cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    return preprocess\n",
    "\n",
    "# Modelo 1: OLS\n",
    "model_1 = Pipeline([\n",
    "    (\"preprocess\", build_preprocess(X_train, scale_numeric=False)),\n",
    "    (\"reg\", LinearRegression()),\n",
    "])\n",
    "\n",
    "# Modelo 2: RidgeCV (elige alpha automáticamente)\n",
    "alphas = np.logspace(-3, 3, 25)\n",
    "model_2 = Pipeline([\n",
    "    (\"preprocess\", build_preprocess(X_train, scale_numeric=True)),\n",
    "    (\"reg\", RidgeCV(alphas=alphas)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8260aa",
   "metadata": {},
   "source": [
    "## 8. Evaluación cuantitativa (RMSE, MAE, R2) y baseline del promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dd00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_model(model, X_tr, y_tr, X_te, y_te):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    pred = model.predict(X_te)\n",
    "    rmse = np.sqrt(mean_squared_error(y_te, pred))\n",
    "    mae  = mean_absolute_error(y_te, pred)\n",
    "    r2   = r2_score(y_te, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "# Baseline: predecir el promedio del target\n",
    "baseline_pred = np.repeat(y_train.mean(), len(y_test))\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_test, baseline_pred))\n",
    "baseline_mae  = mean_absolute_error(y_test, baseline_pred)\n",
    "baseline_r2   = r2_score(y_test, baseline_pred)\n",
    "\n",
    "rmse1, mae1, r21 = eval_model(model_1, X_train, y_train, X_test, y_test)\n",
    "rmse2, mae2, r22 = eval_model(model_2, X_train, y_train, X_test, y_test)\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    {\"Modelo\": \"Baseline (promedio)\", \"RMSE\": baseline_rmse, \"MAE\": baseline_mae, \"R2\": baseline_r2},\n",
    "    {\"Modelo\": \"Modelo 1 (OLS)\", \"RMSE\": rmse1, \"MAE\": mae1, \"R2\": r21},\n",
    "    {\"Modelo\": \"Modelo 2 (RidgeCV)\", \"RMSE\": rmse2, \"MAE\": mae2, \"R2\": r22},\n",
    "]).sort_values(\"RMSE\", ascending=True)\n",
    "\n",
    "display(results)\n",
    "\n",
    "best_row = results[results[\"Modelo\"].str.contains(\"Modelo\")].sort_values(\"RMSE\").iloc[0]\n",
    "best_name = best_row[\"Modelo\"]\n",
    "best_model = model_1 if best_name == \"Modelo 1 (OLS)\" else model_2\n",
    "\n",
    "print(\"Mejor modelo (por RMSE):\", best_name)\n",
    "\n",
    "if best_name == \"Modelo 2 (RidgeCV)\":\n",
    "    print(\"Alpha seleccionado (RidgeCV):\", best_model.named_steps[\"reg\"].alpha_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8549c7",
   "metadata": {},
   "source": [
    "## 9. Importancia de variables: coeficientes del mejor modelo\n",
    "\n",
    "Extraemos:\n",
    "- nombres de features (después del preprocesamiento)\n",
    "- coeficientes del regresor (OLS o Ridge)\n",
    "\n",
    "Se ordena por valor absoluto para reportar variables más influyentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cafeaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "preprocess_step = best_model.named_steps[\"preprocess\"]\n",
    "feature_names = preprocess_step.get_feature_names_out()\n",
    "\n",
    "coefs = best_model.named_steps[\"reg\"].coef_\n",
    "\n",
    "coef_df = (\n",
    "    pd.DataFrame({\"Feature\": feature_names, \"Coef\": coefs})\n",
    "      .assign(AbsCoef=lambda d: d[\"Coef\"].abs())\n",
    "      .sort_values(\"AbsCoef\", ascending=False)\n",
    ")\n",
    "\n",
    "display(coef_df.head(25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5183bf6",
   "metadata": {},
   "source": [
    "## 10. Validación visual de supuestos (residuos)\n",
    "\n",
    "Para apoyar interpretación:\n",
    "- residuos vs predicción\n",
    "- histograma de residuos\n",
    "- QQ plot\n",
    "\n",
    "Esto no prueba formalmente, pero es suficiente para la etapa cualitativa del laboratorio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4539151",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_pred, residuals, alpha=0.4)\n",
    "plt.axhline(0)\n",
    "plt.title(\"Residuos vs Predicción\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Residuo (y - y_hat)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Histograma de residuos\")\n",
    "plt.xlabel(\"Residuo\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()\n",
    "\n",
    "import scipy.stats as stats\n",
    "plt.figure(figsize=(6,4))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ-plot de residuos\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e49af5",
   "metadata": {},
   "source": [
    "## 11. Entrenar el mejor modelo con TODO el train y predecir el test no etiquetado\n",
    "\n",
    "Reglas importantes:\n",
    "- Limpiar el test original (para construir X_submit).\n",
    "- Exportar usando el **test_raw** (para conservar filas y orden exacto del archivo entregable).\n",
    "- Alinear columnas con `reindex` para evitar errores por columnas faltantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12690935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Train completo (ya limpio) para entrenar final\n",
    "X_full = train.drop(columns=[TARGET] + DROP_ALWAYS).copy()\n",
    "y_full = train[TARGET].copy()\n",
    "\n",
    "# 2) Partimos del test ORIGINAL para conservar filas y orden del archivo entregable\n",
    "test_submit = clean_common(test_raw.copy(), CAT_COLS)\n",
    "\n",
    "# 3) Armamos X_submit y lo alineamos con X_full\n",
    "X_submit = test_submit.drop(columns=DROP_ALWAYS, errors=\"ignore\").copy()\n",
    "X_submit = X_submit.reindex(columns=X_full.columns)\n",
    "\n",
    "# 4) Entrenar y predecir\n",
    "best_model.fit(X_full, y_full)\n",
    "test_pred = best_model.predict(X_submit)\n",
    "\n",
    "# 5) Exportar el archivo final con el mismo formato del test (separador ;)\n",
    "out = test_raw.copy()\n",
    "out[TARGET] = test_pred\n",
    "\n",
    "output_path = \"Datos Test Lab 1.csv\"\n",
    "out.to_csv(output_path, index=False, sep=\";\")\n",
    "\n",
    "print(\"Archivo generado para entrega:\", output_path)\n",
    "display(out.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3cd448",
   "metadata": {},
   "source": [
    "## 12. Preguntas de análisis de resultados (responde aquí)\n",
    "\n",
    "Responde directamente las preguntas del enunciado usando tus salidas:\n",
    "\n",
    "1) Coeficientes del mejor modelo (usa `coef_df`).\n",
    "2) Mejor rendimiento (usa `results`) e interpretación de RMSE, MAE, R2.\n",
    "3) Variables seleccionadas (top de `coef_df`) e interpretación en el contexto AlpesHearth.\n",
    "4) Representación matemática:\n",
    "   - OLS: β = (XᵀX)⁻¹Xᵀy\n",
    "   - Ridge: β = (XᵀX + αI)⁻¹Xᵀy\n",
    "5) Dos sesgos: selección (muestra no representativa), medición (laboratorios con error), etc.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
